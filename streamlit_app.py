	# streamlit_app.py
	import streamlit as st
	import requests
	import json
		# --- 1. æç¤ºè¯æ¨¡æ¿ (å®šä¹‰GLM-4.6çš„è§’è‰²å’Œä»»åŠ¡) ---
	SYSTEM_PROMPT = """
	ä½ æ˜¯ä¸€ä½é¡¶å°–çš„ç¾å›½ç§»æ°‘å¾‹å¸ˆé¡¾é—®ï¼ŒåŒæ—¶ç²¾é€šå­¦æœ¯æ•°æ®åˆ†æå’ŒUSCISï¼ˆç¾å›½å…¬æ°‘åŠç§»æ°‘æœåŠ¡å±€ï¼‰çš„NIWï¼ˆå›½å®¶åˆ©ç›Šè±å…ï¼‰å’ŒEB-1Aï¼ˆæ°å‡ºäººæ‰ï¼‰ç”³è¯·å®¡æŸ¥é€»è¾‘ã€‚
	ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„ç§‘ç ”èƒŒæ™¯èµ„æ–™ï¼Œå¹¶æ¨¡æ‹ŸUSCISçš„å®¡æŸ¥æ ‡å‡†ï¼Œç»™å‡ºä¸€ä»½å…¨é¢ã€ä¸“ä¸šçš„è¯„ä¼°æŠ¥å‘Šã€‚
	ä½ å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
	1.  ä½ çš„å…¨éƒ¨å›ç­”å¿…é¡»æ˜¯ä¸€ä¸ªå•ä¸€ã€æœ‰æ•ˆçš„JSONå¯¹è±¡ã€‚
	2.  ä¸è¦åœ¨JSONå¯¹è±¡å‰åæ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–ä»»ä½•å…¶ä»–å†…å®¹ã€‚
	3.  å¦‚æœæ— æ³•åˆ†æï¼Œè¯·è¿”å›ä¸€ä¸ªåŒ…å« "error": "Unable to process the input." çš„JSONå¯¹è±¡ã€‚
	JSONå¯¹è±¡çš„ç»“æ„å¿…é¡»å¦‚ä¸‹ï¼š
	{
	  "analysis_summary": {
	    "field_of_expertise": "ç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸ",
	    "key_achievements": "ä¸»è¦æˆå°±çš„ç®€è¦æ€»ç»“"
	  },
	  "prong_analysis": {
	    "prong_1": {
	      "score": 8,
	      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆæ»¡è¶³æˆ–ä¸æ»¡è¶³Substantial Merit and National Importanceã€‚",
	      "suggestions": "é’ˆå¯¹Prong 1çš„è¡¥å¼ºå»ºè®®ã€‚"
	    },
	    "prong_2": {
	      "score": 7,
	      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆç”³è¯·äººWell-Positioned to Advance the Fieldã€‚",
	      "suggestions": "é’ˆå¯¹Prong 2çš„è¡¥å¼ºå»ºè®®ã€‚"
	    },
	    "prong_3": {
	      "score": 9,
	      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆBenefit to the U.S. outweighs Labor Certificationã€‚",
	      "suggestions": "é’ˆå¯¹Prong 3çš„è¡¥å¼ºå»ºè®®ã€‚"
	    }
	  },
	  "overall_assessment": {
	    "total_score": 24,
	    "success_probability_niw": "é«˜",
	    "success_probability_eb1a": "ä¸­",
	    "overall_suggestions": "ç»¼åˆè¡¥å¼ºå»ºè®®ï¼ŒåŒ…æ‹¬è¯æ®ç±»å‹ã€å¯»æ‰¾æ¨èä¿¡çš„äººé€‰ç­‰ã€‚"
	  },
	  "future_plan_draft": [
	    "ç¬¬ä¸€æ¡æœªæ¥è®¡åˆ’ï¼Œä¸ç”³è¯·äººç ”ç©¶æ–¹å‘è¡”æ¥ï¼Œä½“ç°ç¾å›½å›½å®¶æ„ä¹‰ã€‚",
	    "ç¬¬äºŒæ¡æœªæ¥è®¡åˆ’ï¼Œè¯­è¨€ç§¯æã€å¯ä¿¡ã€æœ‰è¡ŒåŠ¨è·¯çº¿ã€‚",
	    "ç¬¬ä¸‰æ¡æœªæ¥è®¡åˆ’ï¼Œå¯ä»¥æ¶‰åŠæ•™å­¦ã€åˆä½œæˆ–æŠ€æœ¯è½¬åŒ–ã€‚"
	  ]
	}
	"""
	USER_PROMPT_TEMPLATE = """
	è¯·æ ¹æ®ä»¥ä¸‹ç”³è¯·äººæä¾›çš„ç§‘ç ”èµ„æ–™ï¼Œè¿›è¡ŒNIW/EB-1Aæ™ºèƒ½è¯„ä¼°ã€‚
	ç”³è¯·äººç§‘ç ”èµ„æ–™ï¼š
	---
	{user_input}
	---
	è¯·ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯ä¸­å®šä¹‰çš„JSONæ ¼å¼è¾“å‡ºä½ çš„è¯„ä¼°æŠ¥å‘Šã€‚
	"""
	# --- 2. æ ¸å¿ƒå‡½æ•° (ç”¨äºè°ƒç”¨GLM-4.6 API) ---
	API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
	# åœ¨éƒ¨ç½²æ—¶ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡Streamlit Secretsæ¥ç®¡ç†è¿™ä¸ªå¯†é’¥
	# åœ¨æœ¬åœ°æµ‹è¯•æ—¶ï¼Œä½ å¯ä»¥ç›´æ¥åœ¨è¿™é‡Œå¡«å…¥ä½ çš„API Key
	API_KEY = st.secrets["ZHIPU_API_KEY"] 
	def get_glm_assessment(user_input_text: str) -> dict:
	    """
	    è°ƒç”¨GLM-4.6æ¨¡å‹è·å–NIW/EB-1Aè¯„ä¼°æŠ¥å‘Š
	    Args:
	        user_input_text (str): ç”¨æˆ·è¾“å…¥çš„ç§‘ç ”èµ„æ–™
	    Returns:
	        dict: è§£æåçš„JSONè¯„ä¼°æŠ¥å‘Šï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
	    """
	    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
	    user_prompt = USER_PROMPT_TEMPLATE.format(user_input=user_input_text)
	    payload = {"model": "glm-4.6", "messages": [{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": user_prompt}], "temperature": 0.2}
	    try:
	        response = requests.post(API_URL, headers=headers, json=payload)
	        response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥åˆ™æŠ›å‡ºå¼‚å¸¸
	        content = response.json()['choices'][0]['message']['content']
	        assessment_report = json.loads(content)
	        return assessment_report
	    except requests.exceptions.RequestException as e:
	        return {"error": f"API request failed: {e}"}
	    except json.JSONDecodeError:
	        return {"error": "Failed to decode JSON from model response.", "raw_content": content if 'content' in locals() else "N/A"}
	    except KeyError:
	        return {"error": "Unexpected API response structure.", "raw_response": response.text}
	# --- 3. Streamlit å‰ç«¯ç•Œé¢ ---
	st.set_page_config(page_title="NIW/EB-1A æ™ºèƒ½è¯„ä¼°åŠ©æ‰‹", layout="wide")
	st.title("ğŸ§‘â€âš–ï¸ NIW / EB-1A æ™ºèƒ½è¯„ä¼°åŠ©æ‰‹")
	st.markdown("åŸºäº GLM-4.6 æ¨¡å‹ï¼Œæ¨¡æ‹Ÿ USCIS å®¡æŸ¥é€»è¾‘ï¼Œä¸ºæ‚¨çš„ç”³è¯·æä¾›ä¸“ä¸šè¯„ä¼°å’Œå»ºè®®ã€‚")
	# ä½¿ç”¨ st.session_state æ¥ç¼“å­˜ç”¨æˆ·è¾“å…¥ï¼Œé¿å…é¡µé¢åˆ·æ–°æ—¶ä¸¢å¤±
	if 'user_input' not in st.session_state:
	    st.session_state.user_input = ""
	with st.form("assessment_form"):
	    st.subheader("ç¬¬ä¸€æ­¥ï¼šè¯·è¾“å…¥æ‚¨çš„ç§‘ç ”èµ„æ–™")
	    user_input = st.text_area(
	        "è¯·è¯¦ç»†æè¿°æ‚¨çš„ç ”ç©¶æ–¹å‘ã€å‘è¡¨çš„é‡è¦è®ºæ–‡ï¼ˆæœŸåˆŠã€å½±å“å› å­ã€å¼•ç”¨æ¬¡æ•°ï¼‰ã€å®¡ç¨¿ç»å†ã€è·å¥–æƒ…å†µã€å›½é™…åˆä½œç­‰ã€‚ä¿¡æ¯è¶Šè¯¦ç»†ï¼Œè¯„ä¼°è¶Šå‡†ç¡®ã€‚",
	        height=300,
	        value=st.session_state.user_input
	    )
	    submitted = st.form_submit_button("å¼€å§‹æ™ºèƒ½è¯„ä¼°")
	    if submitted:
	        if not user_input.strip():
	            st.warning("è¯·è¾“å…¥æ‚¨çš„ç§‘ç ”èµ„æ–™åå†è¿›è¡Œè¯„ä¼°ã€‚")
	        else:
	            st.session_state.user_input = user_input
	            with st.spinner('ğŸ¤– GLM-4.6 æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™...'):
	                report = get_glm_assessment(user_input)
	            if "error" in report:
	                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {report['error']}")
	                if "raw_content" in report:
	                    with st.expander("æŸ¥çœ‹æ¨¡å‹åŸå§‹è¾“å‡º"):
	                        st.code(report['raw_content'])
	            else:
	                st.success("âœ… è¯„ä¼°å®Œæˆï¼")
	                # --- 4. ç»“æœå±•ç¤º ---
	                st.header("è¯„ä¼°æŠ¥å‘Š")
	                # åˆ†ææ‘˜è¦
	                st.subheader("ğŸ“„ åˆ†ææ‘˜è¦")
	                col1, col2 = st.columns(2)
	                col1.metric("ä¸“ä¸šé¢†åŸŸ", report['analysis_summary']['field_of_expertise'])
	                col2.metric("å…³é”®æˆå°±", report['analysis_summary']['key_achievements'])
	                # Prong åˆ†æ
	                st.subheader("âš–ï¸ USCIS Prong è¯¦ç»†åˆ†æ")
	                for prong_name, prong_data in report['prong_analysis'].items():
	                    with st.expander(f"Prong {prong_name.split('_')[-1]}: Score {prong_data['score']}/10"):
	                        st.write(f"**è®ºè¯é€»è¾‘:** {prong_data['reasoning']}")
	                        st.info(f"**è¡¥å¼ºå»ºè®®:** {prong_data['suggestions']}")
	                # ç»¼åˆè¯„ä¼°
	                st.subheader("ğŸ“Š ç»¼åˆè¯„ä¼°")
	                col_niw, col_eb1a, col_score = st.columns(3)
	                col_niw.metric("NIW æˆåŠŸæ¦‚ç‡", report['overall_assessment']['success_probability_niw'])
	                col_eb1a.metric("EB-1A æˆåŠŸæ¦‚ç‡", report['overall_assessment']['success_probability_eb1a'])
	                col_score.metric("ç»¼åˆå¾—åˆ†", report['overall_assessment']['total_score'])
	                st.write(f"**ç»¼åˆå»ºè®®:** {report['overall_assessment']['overall_suggestions']}")
	                # Future Plan
	                st.subheader("ğŸ§­ Future Plan å†™ä½œå»ºè®®")
	                for i, plan in enumerate(report['future_plan_draft']):

	                    st.write(f"{i+1}. {plan}")
