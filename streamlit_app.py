import os
import re
import json
import requests
import streamlit as st
from collections import defaultdict

# -----------------------------
# 0) å…¨å±€é…ç½®
# -----------------------------
API_URL = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
MODEL_ID = "GLM-4.6"  # ç»Ÿä¸€ä½¿ç”¨è¿™ä¸ªå¤§å°å†™

st.set_page_config(page_title="NIW/EB-1A æ™ºèƒ½è¯„ä¼°åŠ©æ‰‹", layout="wide")
st.title("ğŸ§‘â€âš–ï¸ NIW / EB-1A æ™ºèƒ½è¯„ä¼°åŠ©æ‰‹")
st.markdown("åŸºäº **GLM-4.6**ï¼Œæ¨¡æ‹Ÿ USCIS å®¡æŸ¥é€»è¾‘ï¼Œè¾“å‡ºï¼šProng åˆ†æã€æˆåŠŸç‡ä¸ Future Planã€‚")

# -----------------------------
# 1) æç¤ºè¯
# -----------------------------
SYSTEM_PROMPT = r"""
ä½ æ˜¯ä¸€ä½é¡¶å°–çš„ç¾å›½ç§»æ°‘å¾‹å¸ˆé¡¾é—®ï¼ŒåŒæ—¶ç²¾é€šå­¦æœ¯æ•°æ®åˆ†æå’ŒUSCISï¼ˆç¾å›½å…¬æ°‘åŠç§»æ°‘æœåŠ¡å±€ï¼‰çš„NIWï¼ˆå›½å®¶åˆ©ç›Šè±å…ï¼‰å’ŒEB-1Aï¼ˆæ°å‡ºäººæ‰ï¼‰ç”³è¯·å®¡æŸ¥é€»è¾‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„ç§‘ç ”èƒŒæ™¯èµ„æ–™ï¼Œå¹¶æ¨¡æ‹ŸUSCISçš„å®¡æŸ¥æ ‡å‡†ï¼Œç»™å‡ºä¸€ä»½å…¨é¢ã€ä¸“ä¸šçš„è¯„ä¼°æŠ¥å‘Šã€‚
ä½ å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1.  ä½ çš„å…¨éƒ¨å›ç­”å¿…é¡»æ˜¯ä¸€ä¸ªå•ä¸€ã€æœ‰æ•ˆçš„JSONå¯¹è±¡ã€‚
2.  ä¸è¦åœ¨JSONå¯¹è±¡å‰åæ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–ä»»ä½•å…¶ä»–å†…å®¹ã€‚
3.  å¦‚æœæ— æ³•åˆ†æï¼Œè¯·è¿”å›ä¸€ä¸ªåŒ…å« "error": "Unable to process the input." çš„JSONå¯¹è±¡ã€‚
JSONå¯¹è±¡çš„ç»“æ„å¿…é¡»å¦‚ä¸‹ï¼š
{
  "analysis_summary": {
    "field_of_expertise": "ç”³è¯·äººçš„ä¸“ä¸šé¢†åŸŸ",
    "key_achievements": "ä¸»è¦æˆå°±çš„ç®€è¦æ€»ç»“"
  },
  "prong_analysis": {
    "prong_1": {
      "score": 8,
      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆæ»¡è¶³æˆ–ä¸æ»¡è¶³Substantial Merit and National Importanceã€‚",
      "suggestions": "é’ˆå¯¹Prong 1çš„è¡¥å¼ºå»ºè®®ã€‚"
    },
    "prong_2": {
      "score": 7,
      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆç”³è¯·äººWell-Positioned to Advance the Fieldã€‚",
      "suggestions": "é’ˆå¯¹Prong 2çš„è¡¥å¼ºå»ºè®®ã€‚"
    },
    "prong_3": {
      "score": 9,
      "reasoning": "è®ºè¯è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆBenefit to the U.S. outweighs Labor Certificationã€‚",
      "suggestions": "é’ˆå¯¹Prong 3çš„è¡¥å¼ºå»ºè®®ã€‚"
    }
  },
  "overall_assessment": {
    "total_score": 24,
    "success_probability_niw": "é«˜",
    "success_probability_eb1a": "ä¸­",
    "overall_suggestions": "ç»¼åˆè¡¥å¼ºå»ºè®®ï¼ŒåŒ…æ‹¬è¯æ®ç±»å‹ã€å¯»æ‰¾æ¨èä¿¡çš„äººé€‰ç­‰ã€‚"
  },
  "future_plan_draft": [
    "ç¬¬ä¸€æ¡æœªæ¥è®¡åˆ’ï¼Œä¸ç”³è¯·äººç ”ç©¶æ–¹å‘è¡”æ¥ï¼Œä½“ç°ç¾å›½å›½å®¶æ„ä¹‰ã€‚",
    "ç¬¬äºŒæ¡æœªæ¥è®¡åˆ’ï¼Œè¯­è¨€ç§¯æã€å¯ä¿¡ã€æœ‰è¡ŒåŠ¨è·¯çº¿ã€‚",
    "ç¬¬ä¸‰æ¡æœªæ¥è®¡åˆ’ï¼Œå¯ä»¥æ¶‰åŠæ•™å­¦ã€åˆä½œæˆ–æŠ€æœ¯è½¬åŒ–ã€‚"
  ]
}
"""

USER_PROMPT_TEMPLATE = """
è¯·æ ¹æ®ä»¥ä¸‹ç”³è¯·äººæä¾›çš„ç§‘ç ”èµ„æ–™ï¼Œè¿›è¡ŒNIW/EB-1Aæ™ºèƒ½è¯„ä¼°ã€‚
ç”³è¯·äººç§‘ç ”èµ„æ–™ï¼š
---
{user_input}
---
è¯·ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯ä¸­å®šä¹‰çš„JSONæ ¼å¼è¾“å‡ºä½ çš„è¯„ä¼°æŠ¥å‘Šã€‚
"""

# -----------------------------
# 2) å·¥å…·å‡½æ•°
# -----------------------------
def get_api_key():
    # ä¼˜å…ˆ secrets â†’ ç¯å¢ƒå˜é‡ â†’ é¡µé¢è¾“å…¥
    key = None
    try:
        key = st.secrets["ZHIPU_API_KEY"]
    except Exception:
        key = os.getenv("ZHIPU_API_KEY")

    if not key:
        st.info("æœªæ£€æµ‹åˆ° API Keyï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥ï¼ˆä»…ä¿å­˜åœ¨æœ¬é¡µä¼šè¯ä¸­ï¼‰ã€‚")
        key = st.text_input("ZHIPU_API_KEY", type="password")
        if key:
            st.session_state["_ZHIPU_API_KEY_USER"] = key
        else:
            key = st.session_state.get("_ZHIPU_API_KEY_USER")

    return key

def strip_code_fences(text: str) -> str:
    # å»æ‰ ```json ... ``` æˆ– ``` ... ``` å›´æ 
    text = re.sub(r"^```.*?\n", "", text.strip(), flags=re.S)
    text = re.sub(r"\n```$", "", text.strip(), flags=re.S)
    return text.strip()

def extract_first_json(text: str) -> str:
    # ä¿åº•ï¼šæå–ç¬¬ä¸€ä¸ªâ€œ{ ... }â€å¤§æ‹¬å·åŒ…è£¹çš„å¯¹è±¡
    s = strip_code_fences(text)
    start = s.find("{")
    end = s.rfind("}")
    if start != -1 and end != -1 and end > start:
        return s[start:end+1]
    return s  # å°±æŒ‰åŸæ–‡è¿”å›ï¼Œäº¤ç»™ json.loads å»å°è¯•

def call_glm(user_input_text: str, api_key: str) -> dict:
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": MODEL_ID,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": USER_PROMPT_TEMPLATE.format(user_input=user_input_text)}
        ],
        "temperature": 0.2
    }
    try:
        resp = requests.post(API_URL, headers=headers, json=payload, timeout=60)
        resp.raise_for_status()
        data = resp.json()
        content = data["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        return {"error": f"API request failed: {e}", "raw_response": getattr(resp, "text", "")}
    except (KeyError, ValueError) as e:
        return {"error": f"Unexpected API response structure: {e}", "raw_response": getattr(resp, "text", "")}

    # å°è¯•è§£æä¸¥æ ¼ JSON
    raw = extract_first_json(content)
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        return {"error": "Failed to decode JSON from model response.", "raw_content": content}

# -----------------------------
# 3) é¡µé¢ä¸æµç¨‹
# -----------------------------
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

api_key = get_api_key()
with st.form("assessment_form"):
    st.subheader("ç¬¬ä¸€æ­¥ï¼šè¯·è¾“å…¥æ‚¨çš„ç§‘ç ”èµ„æ–™")
    user_input = st.text_area(
        "è¯·è¯¦ç»†æè¿°ç ”ç©¶æ–¹å‘ã€ä»£è¡¨è®ºæ–‡ï¼ˆæœŸåˆŠ/å½±å“å› å­/å¼•ç”¨ï¼‰ã€å®¡ç¨¿ç»å†ã€å¥–é¡¹ã€åˆä½œç­‰ã€‚",
        height=300,
        value=st.session_state.user_input
    )
    submitted = st.form_submit_button("å¼€å§‹æ™ºèƒ½è¯„ä¼°")

if submitted:
    if not api_key:
        st.error("ç¼ºå°‘ ZHIPU_API_KEYï¼šè¯·é…ç½® Streamlit Secrets æˆ–åœ¨é¡µé¢è¾“å…¥æ¡†é‡Œå¡«å…¥ã€‚")
        st.stop()
    if not user_input.strip():
        st.warning("è¯·è¾“å…¥ç§‘ç ”èµ„æ–™åå†è¯„ä¼°ã€‚")
        st.stop()

    st.session_state.user_input = user_input
    with st.spinner("ğŸ¤– GLM-4.6 æ­£åœ¨åˆ†æä¸­..."):
        report = call_glm(user_input, api_key)

    if "error" in report:
        st.error(f"åˆ†æå¤±è´¥ï¼š{report['error']}")
        if "raw_content" in report:
            with st.expander("æŸ¥çœ‹æ¨¡å‹åŸå§‹è¾“å‡º"):
                st.code(report["raw_content"])
        if "raw_response" in report:
            with st.expander("æŸ¥çœ‹APIåŸå§‹å“åº”"):
                st.code(report["raw_response"])
        st.stop()

    # -------------------------
    # 4) ç»“æœå±•ç¤º
    # -------------------------
    st.success("âœ… è¯„ä¼°å®Œæˆï¼")
    st.header("è¯„ä¼°æŠ¥å‘Š")

    # åˆ†ææ‘˜è¦
    st.subheader("ğŸ“„ åˆ†ææ‘˜è¦")
    col1, col2 = st.columns(2)
    col1.write(f"**ä¸“ä¸šé¢†åŸŸï¼š** {report['analysis_summary'].get('field_of_expertise','-')}")
    col2.write(f"**å…³é”®æˆå°±ï¼š** {report['analysis_summary'].get('key_achievements','-')}")

    # Prong åˆ†æ
    st.subheader("âš–ï¸ USCIS Prong è¯¦ç»†åˆ†æ")
    for prong_key in ("prong_1", "prong_2", "prong_3"):
        pr = report.get("prong_analysis", {}).get(prong_key, {})
        score = pr.get("score", "-")
        with st.expander(f"{prong_key.replace('_',' ').title()}  |  Score: {score}/10"):
            st.write(f"**è®ºè¯é€»è¾‘ï¼š** {pr.get('reasoning','-')}")
            st.info(f"**è¡¥å¼ºå»ºè®®ï¼š** {pr.get('suggestions','-')}")

    # ç»¼åˆè¯„ä¼°
    st.subheader("ğŸ“Š ç»¼åˆè¯„ä¼°")
    oa = report.get("overall_assessment", {})
    c1, c2, c3 = st.columns(3)
    c1.metric("NIW æˆåŠŸæ¦‚ç‡", oa.get("success_probability_niw", "-"))
    c2.metric("EB-1A æˆåŠŸæ¦‚ç‡", oa.get("success_probability_eb1a", "-"))
    c3.metric("ç»¼åˆå¾—åˆ†", oa.get("total_score", "-"))
    st.write(f"**ç»¼åˆå»ºè®®ï¼š** {oa.get('overall_suggestions','-')}")

    # Future Plan
    st.subheader("ğŸ§­ Future Plan å†™ä½œå»ºè®®")
    for i, plan in enumerate(report.get("future_plan_draft", []), start=1):
        st.write(f"{i}. {plan}")

